{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Monitoring BYOC with Batch Records for Near Real-time Inference\n",
    "\n",
    "This AWS code sample will demonstrate how to use Amazon SageMaker Model Monitoring when sending a “batch” of multiple inference records to an Amazon SageMaker Endpoint. For this Model Monitoring example, we will be focusing on Model Quality Monitoring (MQM). \n",
    "\n",
    "\n",
    "This notebook will execute the following steps:\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. An AI/ML Developer will train an Amazon SageMaker Model and create Model Quality Baseline artifacts (e.g. F1-Score, Accuracy of model) and save to S3\n",
    "2. An AI/ML Developer will create an Amazon SageMaker Endpoint with SageMaker Model and enable data capture\n",
    "3. User/Application will send 1 payload with multiple inference records to an Amazon Endpoint. The user will receive a single payload response showing the output per inference record.  Since there are multiple inference records per request, we would need to parse the metric/statistic for every payload (containing multiple inference records ) for model quality.\n",
    "4. User/Application will create ground truth data given predictions and store to Amazon S3\n",
    "5. Create BYOC and push to ECR\n",
    "6. A SageMaker Model Monitor Job using a BYOC will be created to:\n",
    "    1. Process the “batch” records to single records from Capture Request/Responses\n",
    "    2. Merge step (A) with ground truth data submitted by user\n",
    "    3. Compare evaluation of (A) and (B) with baseline data artifacts from step (1)\n",
    "    4. Update the calculated metrics in Amazon Cloudwatch and output constraint violations report (if violations are present)\n",
    "7. Use SageMaker Studio Classic Endpoint console to observe Model Monitoring reports\n",
    "    \n",
    "\n",
    "These steps are represented in the architecture diagram below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![architecture image](images/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE:__ You will need permissions to the following AWS SageMaker, S3, and other services\n",
    "\n",
    "* Amazon SageMaker Processing Jobs\n",
    "* Amazon SageMaker Training Jobs\n",
    "* Amazon SageMaker Models\n",
    "* Amazon SageMaker Endpoint\n",
    "* Amazon SageMaker Model Monitor\n",
    "* Amazon CodeBuild\n",
    "* Amazon ECR\n",
    "* Amazon S3 (default SageMaker Bucket)\n",
    "\n",
    "We recommend using the SageMaker Full Access IAM role for best user experience. However, if this isn't possible please either the required permissions for the services above or modify the notebook as needed given your AWS configurations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite recommendations\n",
    "* Amazon SageMaker Studio Classic - We recommend executing this notebook in a SageMaker Studio classic environment. To learn more about setting up Amazon SageMaker Studio please read [here](https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-quick-start.html)\n",
    "* Use an IAM role with the permissions mentioned earlier when setting up your Amazon SageMaker Studio environment. Otherwise, use this role when executing this notebook. \n",
    "* In your Amazon SageMaker Studio Classic environment, open a system terminal and use git operations to clone this notebook's [github repository](https://github.com/aws-samples/customized-model-monitoring-for-near-real-time-batch-inference-with-amazon-sagemaker/tree/main)\n",
    "* When launching this notebook in Amazon SageMaker Studio Classic, please use an instance size of `ml.t3.medium` with a kernel of `Data Science 3.0`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Environment Variables\n",
    "\n",
    "Here we import libraries from the Amazon SageMaker Python SDK, where we will use a default Amazon SageMaker Bucket. We will use the public dataset [forest coverage type](https://archive.ics.uci.edu/dataset/31/covertype) which is accessible through the SKlearn API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.session.Session()\n",
    "account_id = sess.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "bucket = sagemaker.session.Session().default_bucket() # change bucket name here if needed\n",
    "prefix_name = \"sagemaker-model-monitor-byoc-batch-records-endpoint\"\n",
    "train_data_path = f's3://{bucket}/{prefix_name}/training-data/test/test.csv'\n",
    "validation_data_path = f's3://{bucket}/{prefix_name}/training-data/validation/validation.csv'\n",
    "test_data_path = f's3://{bucket}/{prefix_name}/training-data/test/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Training Data\n",
    "\n",
    "Here we will execute an Amazon SageMaker Training Job using the XGBoost Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = fetch_covtype(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use base 0 for ordinal target\n",
    "data.target = data.target.apply(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.10, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Data To S3 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save Training Dataset\n",
    "pd.concat([y_train, X_train], axis=1).to_csv(train_data_path, index=False)\n",
    "\n",
    "## Save Validation path\n",
    "pd.concat([y_val, X_val], axis=1).to_csv(validation_data_path, index=False)\n",
    "\n",
    "## Save Test Dataset\n",
    "pd.concat([y_test, X_test], axis=1).to_csv(test_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.36,\n",
    "    \"gamma\": 2.88,\n",
    "    \"min_child_weight\": 9.89,\n",
    "    \"subsample\": 0.77,\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": 7,\n",
    "    \"num_round\": 50\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"./src/train.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"1.5-1\",\n",
    "    output_path=f's3://{bucket}/{prefix_name}/models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_estimator.fit(\n",
    "    {\n",
    "        \"train\": train_data_path,\n",
    "        \"validation\": validation_data_path\n",
    "    },\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Statistics and Constraints files\n",
    "\n",
    "Here we wil create metadata JSON files based on model evaluation metrics, that will be used in the SageMaker Model Quality Monitoring Job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Review *validation:accuracy* metrics from recent Training Job__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analytics = TrainingJobAnalytics(\n",
    "    training_job_name=xgb_estimator.jobs[-1].name,\n",
    "    metric_names=[\n",
    "        \"validation:accuracy\",\n",
    "        \"train:mlogloss\",\n",
    "        \"validation:mlogloss\"\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dataframe = analytics.dataframe().drop_duplicates([\"metric_name\"],keep=\"last\")\n",
    "print(f\"Accuracy Metric from Training Job:\\n\\n{metrics_dataframe}\")\n",
    "accuracy_value = metrics_dataframe[metrics_dataframe[\"metric_name\"]==\"validation:accuracy\"][\"value\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Statistics File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statistics_dict = {\n",
    "    \"metrics\":{\n",
    "        row[\"metric_name\"]:row[\"value\"] for index, row in metrics_dataframe.iterrows()\n",
    "    }\n",
    "}\n",
    "    \n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(statistics_dict, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"statistics.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! aws s3 cp statistics.json s3://{bucket}/{prefix_name}/model-monitor/mqm/baseline-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Constraints File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constraints_dict = {\n",
    "    \"accuracy\":{\n",
    "        \"threshold\": accuracy_value\n",
    "    }\n",
    "}\n",
    "    \n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(constraints_dict, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"constraints.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! aws s3 cp constraints.json s3://{bucket}/{prefix_name}/model-monitor/mqm/baseline-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm constraints.json statistics.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = xgb_estimator.deploy(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    initial_instance_count=1,\n",
    "    wait=True,\n",
    "    data_capture_config=DataCaptureConfig(\n",
    "        enable_capture=True,\n",
    "        sampling_percentage=100,\n",
    "        destination_s3_uri=f\"s3://{bucket}/{prefix_name}/model-monitor/data-capture\"\n",
    "    ),\n",
    "    source_dir=\"./src\",\n",
    "    entry_point=\"inference.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Invoke SageMaker Endpoint with Muliple Payloads and Collect Ground Truth\n",
    "\n",
    "In this section, we create ground truth values for each inference invocation. \n",
    "\n",
    "__Note__: Due to the batch inference payload customization, we create specific indexes such as `InferenceId` and `payload_index`, which will be used later when joining with the SageMaker Endpoint data capture within the SageMaker Model Monitoring Job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Ground Truth for 2 inference records__\n",
    "\n",
    "Since we are issuing a payload with multiple inference records, we group them by an `InferenceId`, which we will reference when invoking the Amazon SageMaker Endpoint.\n",
    "\n",
    "For simplicity, we use the test dataset which provides records for inference along with labels for ground truth examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_id = 0\n",
    "ground_truth_df_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "number_of_records = 2\n",
    "test_records = json.dumps(test_df.iloc[0:number_of_records, 1:].to_dict(orient=\"records\"))\n",
    "ground_truth_df = pd.DataFrame(\n",
    "    {\n",
    "        \"InferenceId\": [str(inference_id)] * number_of_records,\n",
    "        \"payload_index\": list(range(number_of_records)),\n",
    "        \"groundTruthLabel\": test_df.iloc[0:number_of_records, 0]\n",
    "    }\n",
    ")\n",
    "ground_truth_df_ls.append(ground_truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Invoking the Amazon SageMaker Endpoint__\n",
    "\n",
    "Here we pass our payload (which includes 2 inference records) to the Amazon SageMaker Endpoint. Please note the use of `InferenceId` which relates to the Amazon SageMaker Ground Truth record(s) we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=test_records,\n",
    "    InferenceId=\"0\"\n",
    ")\n",
    "\n",
    "response_data = json.loads(response[\"Body\"].read().decode())\n",
    "print(\"Multi-record response:\\n\")\n",
    "for record in response_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Execute 100 invocations with multiple Payloads__\n",
    "\n",
    "Here we will invoke the SageMaker Endpoint with payloads containing multiple (i.e. batch) of inference records. Along with this, we create Ground Truth labels for each inference record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_records = 5\n",
    "df_index = 0\n",
    "i = 0\n",
    "while i < 100:\n",
    "    inference_id = i + 1\n",
    "    test_records = json.dumps(test_df.iloc[df_index:df_index+number_of_records, 1:].to_dict(orient=\"records\"))\n",
    "    ground_truth_df = pd.DataFrame(\n",
    "        {\n",
    "            \"InferenceId\": [str(inference_id)] * number_of_records,\n",
    "            \"payload_index\": list(range(number_of_records)),\n",
    "            \"groundTruthLabel\": test_df.iloc[df_index:df_index+number_of_records, 0]\n",
    "        }\n",
    "    )\n",
    "    ground_truth_df_ls.append(ground_truth_df)\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=predictor.endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Accept=\"application/json\",\n",
    "        Body=test_records,\n",
    "        InferenceId=str(inference_id)\n",
    "    )\n",
    "    df_index += number_of_records\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Store Ground Truth in S3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_dataframe = pd.concat(ground_truth_df_ls, axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save ground truth data by partitioned prefix by timestamp\n",
    "timestamp = dt.datetime.now(dt.timezone.utc)\n",
    "timestamp_prefix_parts = [timestamp.year, timestamp.month, timestamp.day, timestamp.hour]\n",
    "data_partition_prefix = \"/\".join([str(ts) for ts in timestamp_prefix_parts])\n",
    "\n",
    "gt_dataframe.to_json(\n",
    "    f\"s3://{bucket}/{prefix_name}/model-monitor/mqm/ground_truth/{predictor.endpoint_name}/{data_partition_prefix}/ground_truth.json\",\n",
    "    orient=\"records\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build BYOC Docker Image\n",
    "\n",
    "Here we use [Amazon SageMaker Studio Image Build CLI](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/) to create a custom docker image that is created from the base [Amazon SageMaker SKLearn image](https://github.com/aws/sagemaker-scikit-learn-container). \n",
    "\n",
    "We will execute a shell script which will install the SageMaker Studio Image Build CLI, build the image, and push to ECR with the repo name:tag of sm-mm-mqm-byoc:1.0. We run this script from the root directory of this repository. To read script, please see `./scripts/build_push_ecr_image.sh` for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Docker file based on image uri__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./docker/Dockerfile\n",
    "# we use the SageMaker pre-built SKLearn image as the base image\n",
    "# for this example, we use the us-east-1 region. If you have a different region\n",
    "# please update the image uri below accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = retrieve(framework=\"sklearn\", region=region,py_version=\"py3\", version=\"1.2-1\")\n",
    "image_uri = f\"FROM {image_uri}\"\n",
    "%store image_uri >>./docker/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile  -a ./docker/Dockerfile\n",
    "\n",
    "RUN python3 -m pip install awswrangler\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ADD ./src/model_quality_monitoring.py /\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"/model_quality_monitoring.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run shell script to build and push Docker image to ECR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! bash ./scripts/build_push_ecr_image.sh ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Amazon SageMaker Model Monitoring Schedule\n",
    "\n",
    "Here we use the Python SageMaker SDK to setup a Amazon SageMaker Model Monitoring Job\n",
    "\n",
    "We will schedule an hourly SageMaker Model Monitoring job using our custom ECR image (i.e. BYOC) for our MQM use case. \n",
    "\n",
    "__Notes__: \n",
    " * You can supply environment variables and entrypoint script arguments to the `ModelMonitor` class and method `create_monitoring_schedule` for further cusotmization. In this example: \n",
    "   * we provide the path `ground_truth_s3_uri_path` as an env variable which we use within the Amazon SageMaker Model Monitoring Job code. \n",
    "   * we provide the `--create-violation-tests` argument which we use within the Amazon SageMaker Model Monitoring Job code to create a violation. This will issue a Cloud Watch Alert for this demonstration. \n",
    " * After creating monitoring job, the `MonitoringType` will have a value of `DataQuality`. This is a default value for this attribute when using a BYOC with SageMaker Model Monitoring, and shound not be confused with Data Quality Monitoring. \n",
    " * We set the SageMaker Model Monitoring schedule to be executed on an hourly basis. For testing purposes, please ensure that both data capture and ground truth are available in S3. You can always re-execute the previous cells in this notebook, to create more dummy data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor.model_monitoring import ModelMonitor, MonitoringOutput\n",
    "from sagemaker.model_monitor.cron_expression_generator import CronExpressionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_mm_mqm = ModelMonitor(\n",
    "    role=role, \n",
    "    image_uri=f\"{account_id}.dkr.ecr.us-east-1.amazonaws.com/sm-mm-mqm-byoc:1.0\", \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge', \n",
    "    base_job_name=\"sm-mm-mqm-byoc\",\n",
    "    sagemaker_session=sess,\n",
    "    env={\n",
    "        \"ground_truth_s3_uri_path\": f\"s3://{bucket}/{prefix_name}/model-monitor/mqm/ground_truth/{predictor.endpoint_name}\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_mm_mqm.create_monitoring_schedule(\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    output=MonitoringOutput(\n",
    "        source=\"/opt/ml/processing/output\",\n",
    "        destination=f\"s3://{bucket}/{prefix_name}/model-monitor/mqm/reports\"\n",
    "    ),\n",
    "    statistics=f\"s3://{bucket}/{prefix_name}/model-monitor/mqm/baseline-data/statistics.json\",\n",
    "    constraints=f\"s3://{bucket}/{prefix_name}/model-monitor/mqm/baseline-data/constraints.json\",\n",
    "    monitor_schedule_name=\"sm-mm-byoc-batch-inf-schedule\",\n",
    "    schedule_cron_expression=CronExpressionGenerator().hourly(),\n",
    "    arguments=[\n",
    "        \"--create-violation-tests\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Verify model monitoring schedule is created__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! aws sagemaker describe-monitoring-schedule --monitoring-schedule-name {sm_mm_mqm.monitoring_schedule_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Observe SageMaker Model Monitor Output\n",
    "\n",
    "Now that the Amazon SageMaker Model Monitor resource is created, the Amazon SageMaker Endpoint was invoked in step 4, we can now observe our SageMaker Model Monitoring results. \n",
    "\n",
    "Since we set the CRON schedule for the SageMaker Model Monitoring Job to be set on an hourly schedule, we’ll view the results at the end of the hour. In SageMaker Studio Classic, by navigating to the SageMaker Endpoint console, you can select the “Monitoring job history” panel to view status reports of the SageMaker Monitoring Job as shown in the screen shot below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![dashboard image](images/model-monitoring-dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an issue is found, you select the monitoring job name to review the report. \n",
    "Here the custom model monitoring metric created in the BYOC flagged an accuracy score violation of -1 (this was done purposely for demonstration with the argument `--create-violation-tests` in step 6). \n",
    "\n",
    "![report image](images/monitoring-job-report.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives you the ability to monitor model quality violations for your custom SageMaker Model Quality Monitoring Job all within the Amazon SageMaker Studio console. If you desire to trigger Amazon CloudWatch Alarms given published CloudWatch Metrics, you must create these CloudWatch Metrics with your BYOC job.\n",
    "\n",
    "For automated alerts for Model Monitoring, creating an Amazon SNS topic is recommended, which email user groups will subscribe to for awareness given a CloudWatch Metric Alarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clean Up\n",
    "\n",
    "Here we remove data capture, delete model monitoring schedule, and delete the Amazon SageMaker Endpoint for cost minimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Captured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 rm s3://{bucket}/{prefix_name}/model-monitor/data-capture/{predictor.endpoint_name} --recursive\n",
    "! aws s3 rm s3://{bucket}/{prefix_name}/model-monitor/mqm/ground_truth/{predictor.endpoint_name} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Monitoring Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_mm_mqm.delete_monitoring_schedule()\n",
    "# wait for Model Monitoring Schedule to be deleted before deleting endpoint\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
